{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f848bee7-0a67-49e1-8b0d-fa652e717514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "059c98a5-d194-4bfd-8c48-ee58c83a81ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://kozigallas.gov.hu/publicsearch.aspx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cac70926",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['gy贸gypedag贸gus','tan谩r','tan铆t贸','贸vodapedag贸gus','orvos', 'v茅dn']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776f6e54-585d-41fb-9c2c-aace4cc3406d",
   "metadata": {},
   "source": [
    "The response is an HTML page which we'll have to parse. So we'll use BeautifulSoup to take the response string and parse the HTML:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd9c446-450e-43af-bf05-dbddc0bcdb98",
   "metadata": {},
   "source": [
    "Let's also add the date and time of retrieval. We'll put the date along with the count into an array so we can easily add it as a row to a CSV.\n",
    "\n",
    "**NOTE** We are using timezone to set UTC as the time on everything, because that is what Github Actions uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "62c41cd8-57e2-441d-bbfd-fc0603f572ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'gy贸gypedag贸gus']\n",
      "['date', 'gy贸gypedag贸gus', 'tan谩r']\n",
      "['date', 'gy贸gypedag贸gus', 'tan谩r', 'tan铆t贸']\n",
      "['date', 'gy贸gypedag贸gus', 'tan谩r', 'tan铆t贸', '贸vodapedag贸gus']\n",
      "['date', 'gy贸gypedag贸gus', 'tan谩r', 'tan铆t贸', '贸vodapedag贸gus', 'orvos']\n",
      "['date', 'gy贸gypedag贸gus', 'tan谩r', 'tan铆t贸', '贸vodapedag贸gus', 'orvos', 'v茅dn']\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "current_date = datetime.now(timezone.utc).strftime(\"%m/%d/%Y\")\n",
    "current_time = datetime.now(timezone.utc).strftime(\"%H:%M:%S\")\n",
    "\n",
    "HEADERS = ['date']\n",
    "FILENAME = 'vacancies_count.csv'\n",
    "\n",
    "for keyword in keywords:\n",
    "    HEADERS.append(keyword)\n",
    "    print(HEADERS)\n",
    "\n",
    "index = 2\n",
    "row = [current_date]\n",
    "\n",
    "for keyword in keywords:\n",
    "    response = send_request(keyword)\n",
    "    html = bs4.BeautifulSoup(response, 'html.parser')\n",
    "    count = html.find(id='ctl00_ContentPlaceHolder1_JobSearchForm1_lblCount').text\n",
    "    row.append(count)\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "if not os.path.isfile(FILENAME):\n",
    "   with open(FILENAME, 'w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(HEADERS)\n",
    "    writer.writerow(row)\n",
    "else: # else it exists so append without writing the header\n",
    "   with open(FILENAME, 'a', newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8898ac57-7dd1-4493-b50e-e16c753eb8c2",
   "metadata": {},
   "source": [
    "Done! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('scraper-hu-teachingjobs-ObU_w_Wc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ece9d11739e89b1147d354ecc72cf95ace2f424d5558e0588f1407042c7b7b80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
